\begin{abstract}
During the current COVID-19 pandemic, a high volume of lung imaging has been generated in the aid of the treating clinician. Importantly, lung inflammation severity, associated with the disease outcome, needs to be precisely quantified. Producing consistent and accurate reporting in high-demand scenarios can be a challenge that can compromise patient care with significant inter- or intra-observer variability in quantifying lung inflammation in a chest CT scan. In this backdrop, automated segmentation has recently been attempted using UNet++, a convolutional neural network (CNN), and results comparable to manual methods have been reported. In this paper, we hypothesize that the desired task can be performed with comparable efficiency using capsule networks with fewer parameters that make use of an advanced vector representation of information and dynamic routing. In this paper, we validate this hypothesis using SegCaps, a capsule network, by direct comparison, individual comparison with CT severity score, and comparing the relative effect on a ML(machine learning)-based prognosis model developed elsewhere. We further provide a scenario, where a combination of UNet++ and SegCaps achieves improved performance compared to individual models.



%SegCaps 


%*** In this paper, we aimed to develop an automated image segmentation algorithm to detect and quantify the inflammation in the lung with the help of CNN and Capsule Network-based models. Convolution neural network(CNNs) has shown great potential over the last few years in medical image segmentation tasks. The new architecture which was introduced by Sabour et al. called Capsule Networks with Dynamic Routing has shown great potential results for digit recognition tasks and on small image classification tasks. The reason behind the success of Capsule Networks lies in the fact that they preserve more information about the input by replacement of max-pooling layers with convolutional strides and dynamic routing. The new proposed architecture named SegCaps introduced by Rodney LaLonde and Ulas Bagci expands the use of Capsule Networks for object segmentation task, we applied the proposed SegCaps to segment infectious region inside the lungs and further compared it with CNN based model named UNet++.
%Various ophthalmic procedures critically depend on high-quality images. For instance, efficiency of teleophthalmology, a framework to bring advanced eye care to remote regions, is determined by the capability of assessing diagnostic quality of ocular fundus photographs (FPs), and rejecting poor-quality ones at the source. In this context, we study algorithmic methods of classifying high- and low-quality FPs.  Crucially, diagnostic quality (DQ) -- determined by clinically, but not necessarily perceptually, significant structures -- is not synonymous with perceptual appeal. Yet, traditional methods handpick features individually (or in small subsets) to meet certain ad hoc perceptual requirements. In contrast, we investigate the efficacy of a comprehensive set of structure-preserving features, systematically generated by a deep scattering network (ScatNet). Specifically, we consider three advanced machine learning classifiers, train each using ScatNet as well as traditional features separately, and demonstrate that the former ensure significantly superior performance for each classifier under multiple criteria including classification accuracy.
\end{abstract}
    